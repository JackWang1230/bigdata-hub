## 依赖管理


Oozie没有合适粒度的依赖管理，只有定时任务级别的依赖，通过配置input和output标记实现

社区版的 Oozie 管理依赖的方式有两种
- 工作流内部的依赖，以 DAG 的形式表示
- 定时工作流可以依赖某一个外部 URI，如 HDFS 文件或目录

#### 存在的一些问题：
- 用户需要提交和管理大量的工作流，工作流分别属于不同的项目，有不同的负责人
- 缺乏版本的概念。修改了工作流之后需要重启，无法查看之前版本的内容。可以考虑用gitlab+CI管理xml文件解决，但也有问题

爱奇艺的改进（Gear）：
- ssh任务负载均衡
    - ssh根据用户指定的多个host，动态根据host上的负载情况选择执行ssh的机器
> 其实这一点Oozie应该也是有的，毕竟跑workflow的时候，是Oozie调度的，运行的机器不固定    
- 工作流节点失败后继续运行非依赖的节点
    - 一个工作流中会有多个并行的DAG执行路线，其中一个具有依赖关系的执行路线的一个节点执行失败，后续的任务不应该被执行，需要kill掉，这个时候Oozie的默认行为是也会把其他并行的线路也kill掉，虽然线路之间不具有依赖关系
    - 需要修改Oozie源码来更改这一默认行为，改为：某个节点失败后，继续运行其他无依赖关系的节点，直到该工作流没有其他节点可运行的时候才kill整个工作流
- 基于HTTP的前置依赖检测
    - 在coordinator实例执行前可以配置一个活多个URI作为该工作流的前置依赖，但所有依赖准备好的时候才开始运行
    - Oozie原生支持的URI有HDFS（支持文件和目录的依赖检测）和HCatalog（支持Hive元数据的依赖检测）两种
    - 不能支持的依赖：
        - 依赖关系存放在mysql中
        - 依赖HDFS上的文件个数，而不是文件或目录
    - 通过一个HTTP服务满足多样化的依赖
- 多种任务类型支持
- 支持定时工作流coordinator之间的依赖
    - 一个工作流DAG不适宜做得太大，而是应该拆分成多个相互依赖的模块工作流，并且能够上下游联动重跑
    - 可以扩展Oozie的依赖检测URIHandler，这样就不需要HDFS done文件标识了，也很容易找到一个工作流的上下游工作流
- 工作流内部并行度控制
    - 工作流内部可能有多个相互平行的作业，用一个fork节点就会同时启动，用顺序执行就会存在一个节点失败影响其他节点的问题
    - 修改Oozie启动任务的机制，引入了工作流内部节点级别的并行度控制，可以指定并行度来控制最多允许多少个节点同时运行
- hadoop作业集成
    - 一般还需要关系hadoop作业的一些问题：
        - 工作流节点背后运行了那几个hadoop job
        - 一个hadoop作业是哪个工作流哪个节点提交的
        - 这些hadoop作业运行时间多长，每天的变化趋势如何
        - 这些hadoop作业消耗了多少资源
    - 需要在ssh、MR、spark、hive等任务类型的基础上的增加hadoop作业集成的支持
- 工作流定义采用yaml而不是xml，降低用户的学习成本
- 代码托管和提交方式 —— GitLab + CI 自动提交，Workflow-as-Code
> Gear 作为工作流调度系统，需要提供一种提交工作流的方式，最好还有版本管理功能。GitLab 是一个可以借助的平台，我们给用户提供了 GitLab 上的 CI（Continuous Integration）脚本，当用户把工作流定义文件（YAML）push 到 GitLab 后，就会自动运行 CI 脚本，将变更提交进 Gear 后台。这样做的好处是，版本管理和 Code review 都可以不费力地实现了。将工作流配置提交进代码库即能自动同步到 Gear，我们将这种方式称为 Workflow-as-Code。

依赖检测：依赖关系不满足的时候，如果一直处于等待状态，那处于同一个Oozie的workflow中下游子工作流也需要等待，应该怎么平衡？
