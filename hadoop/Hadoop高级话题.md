## Hadoop高级话题

### 1. Hadoop架构介绍
- 分布式计算的要求：
    - 拓展性：机器增加，计算和存储能力应该线性增长
    - 容错性：一个节点失败，主要的计算进程本身不会失败或者受到不利影响
    - 可恢复性：如果作业或者其中一部分失败，不应该有数据丢失
> Hadoop精心的设计是如何满足上面的要求的？
- 传统的数据处理更多的关注更强的计算机，因此导致了超级计算机的出现。
- 新软件栈使用由普通计算机组成的集群，以分布式文件系统（块很大、数据冗余特性）为基础。

- HDFS不是通用的文件系统
    - HDFS与基础的文件系统（如ext3）是不同，HDFS是`基于块的文件系统`，其中的文件被分解成块，以此能够存储一个大于单个磁盘空间的文件
    - 为大批量作业而设计的，作业从头到尾顺序读取大文件，与需要寻找特定值的OLTP应用不同
    - 一次写入，多次读取。一旦文件写入HDFS，就无法修改内容，也不能用现有名称去覆盖文件






